# [2025] NTHU_Natural_Language_Processing-IKMLab
This repository provides course materials of the Natural Language Processing course at NTHU (instructor: Prof. Hung-Yu Kao).

|TA Hour||
| :-: | :-: |
|Mon. | 15:30 - 16:30 |
|Wed. | 15:30 - 16:30 |
| Location | 炯朗館(資電館) 635 |

TA email: nthuikmlab@gmail.com

## Course Materials
Slido：[`Slido`](https://app.sli.do/event/5LEEUbdFx33pkrbx5ziDSc)
| Week | Topics | Slide | Video | HW |
|:-:|---|:-:|:-:|:-:|
|W1 | 課程簡介 Syllabus / Introduction to NLP | [`Slide`](./2025/Slides/W0_Syllabus.pdf) [`Slide1`](./2025/Slides/W1_NLP_brief.pdf) | [`Video1`](https://www.youtube.com/live/X7XJcm9wfFA) [`Video2`](https://www.youtube.com/live/0hTqSpoNp4o) |  |
|W2 | 自然語言處理簡介 (1/2) Introduction to NLP (vector space, indexing, parts of speech, phrase structure) | [`Slide2`](./2025/Slides/W2_Word%20embeddings%20and%20Language%20Modeling%20(RNN).pdf) | [`Video1`](https://www.youtube.com/live/6Z0A4JMptT8) [`Video2`](https://www.youtube.com/live/cqp5a39eyJQ?si=1-vj_n2Xe3YwheHz) | [`HW1`](./2025/Assignments/Assignment1) [`Video`](https://youtu.be/nCS3GpHwqr8) |
|W3 | 自然語言處理簡介 (2/2) Introduction to NLP (Language model) | [`Slide3A`](./2025/Slides/W3_Sequence-to-sequence%20Models%20and%20Attention%20Mechanisms.pdf) | [`Video1`](https://www.youtube.com/live/LFeFc0VtKRI) [`Video2`](https://www.youtube.com/live/UZ22K0rmU1g)|  |
|W4 | 基礎文字資料機器學習 (1/2) Basic machine learning for text (Text Classification, NB, NN) |  [`SlideTA`](./2025/Slides/pytorch_tutorial_NTHU_NLP.pdf) [`Slide3B`](./2025/Slides/W3_Transformers.pdf)  | [`Video1`](https://www.youtube.com/live/INIrdjLVMEU) [`Video2`](https://www.youtube.com/live/tr5QyN5TswM) |  |
|W5 | 基礎文字資料機器學習 (2/2) Basic machine learning for text (word embedding, text representation) | [`Slide3C`](./2025/Slides/W3_subword.pdf) | [`Video1`](https://www.youtube.com/live/Dpswwk6UMCc) [`Video2`](https://www.youtube.com/live/FB0fgRTEbJE) | [`HW2`](./2025/Assignments/Assignment2) [`Video`](https://youtu.be/nFQCFaRs0kE) |
|W6 | 文字生成式AI簡介(1/3) Introduction to GAI (text): Word Embeddings, Language Modeling (RNN), Sequence-to-sequence Models, and Attention Mechanisms, Sub-word Tokenization; Transformers | [`Slide4`](./2025/Slides/W4_bert_and_its_family.pdf) | [`Video1`](https://www.youtube.com/live/U5HypcXrIgY) [`Video2`](https://youtube.com/live/RNlcZjzbhDo) |  |
|W7 | *Python for text tutorial (1/2)* |  [`Slide5`](./2025/Slides/W5_decoding.pdf) [`SlideTA`](./2025/Slides/huggingface_tutorial_bert.pdf)| [`Video1`](https://youtube.com/live/NtPrXea8qSE) [`Video2`](https://youtube.com/live/4qDUML9TeHM) [`Video(HuggingFace Tutorial)`](https://www.youtube.com/watch?v=VErSpYgZGiw)|  |
|W8 | *Python for text tutorial (2/2)* |  [`Slide6`](./2025/Slides/W8_GPT3_InstructGPT_RLHF.pdf) | [`Video1`](https://youtube.com/live/w-M9plRRVQc) [`Video2`](youtube.com/live/h-m9wVSx0_s?si=rMAf8DgKzTTTB0cK) |  |
|W9 | 文字生成式AI簡介(2/3) Introduction to GAI (text): ELMo, BERT, GPT, and T5 (BERT and its Family) |  |  |  |
|W10| 文字生成式AI簡介(3/3) Introduction to GAI (text): Decoding Strategies and Evaluations for Natural Language Generation |  |  |  |
|W11| 大語言模型簡介與訓練 (1/3): Large language model concept and training (GPT-3, InstructGPT, RLHF) |  |  |  |
|W12| 大語言模型簡介與訓練 (2/3): Parameter Efficient Fine-Tuning (PEFT) |  |  |  |
|W13| 大語言模型簡介與訓練 (2/3): Introduction and Review technique of Retrieval Augmented Generation (RAG) |  |  |  |
|W14| **Term project presentation (1/3)** |  |  |  |
|W13| 大語言模型簡介與訓練 (2/3): Introduction and Review technique of Retrieval Augmented Generation (RAG) |  |  |  |
|W14| **Term project presentation (1/3)** |  |  |  |
|W15| **Term project presentation (1/3)** |  |  |  |
|W16| **Term project presentation (1/3)** |  |  |  |
|W17| **Term Project (demo) (optional)** |  |  |  |
|W18| **Term Project (demo) (optional)** |  |  |  |
- Italics: *Tutorial*; Bold: **Reporting**
